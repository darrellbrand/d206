{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce3f564",
   "metadata": {},
   "source": [
    "A)\n",
    "\n",
    "\n",
    "One question that could be asked as a telecommunications service provider could be:\n",
    "\n",
    "Can this data set and an analysis of it, including all of it's variables, inform the organization to make better decisions in order to reduce customer churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08681d38",
   "metadata": {},
   "source": [
    "B)\n",
    "\n",
    "\n",
    "\n",
    "| Name                  | Type     | Example                             |\n",
    "|-----------------------|----------|-------------------------------------|\n",
    "| CaseOrder             | int64    | 1                                   |\n",
    "| Customer_id           | object   | K409198                             |\n",
    "| Interaction           | object   | aa90260b-4141-4a24-8e36-b04ce1f4f77b|\n",
    "| City                  | object   | Point Baker                         |\n",
    "| State                 | object   | AK                                  |\n",
    "| County                | object   | Prince of Wales-Hyder               |\n",
    "| Zip                   | int64    | 99927                               |\n",
    "| Lat                   | float64  | 56.25100                            |\n",
    "| Lng                   | float64  | -133.37571                          |\n",
    "| Population            | int64    | 38                                  |\n",
    "| Area                  | object   | Urban                               |\n",
    "| Timezone              | object   | America/Sitka                       |\n",
    "| Job                   | object   | Environmental health practitioner   |\n",
    "| Children              | float64  | 1.0                                 |\n",
    "| Age                   | float64  | 68.0                                |\n",
    "| Education             | object   | Master's Degree                     |\n",
    "| Employment            | object   | Part Time                           |\n",
    "| Income                | float64  | 28561.99                            |\n",
    "| Marital               | object   | Widowed                             |\n",
    "| Gender                | object   | Male                                |\n",
    "| Churn                 | object   | No                                  |\n",
    "| Outage_sec_perweek    | float64  | 6.972566                            |\n",
    "| Email                 | int64    | 10                                  |\n",
    "| Contacts              | int64    | 0                                   |\n",
    "| Yearly_equip_failure  | int64    | 1                                   |\n",
    "| Techie                | object   | No                                  |\n",
    "| Contract              | object   | One year                            |\n",
    "| Port_modem            | object   | Yes                                 |\n",
    "| Tablet                | object   | Yes                                 |\n",
    "| InternetService       | object   | Fiber Optic                         |\n",
    "| Phone                 | object   | Yes                                 |\n",
    "| Multiple              | object   | No                                  |\n",
    "| OnlineSecurity        | object   | Yes                                 |\n",
    "| OnlineBackup          | object   | Yes                                 |\n",
    "| DeviceProtection      | object   | No                                  |\n",
    "| TechSupport           | object   | No                                  |\n",
    "| StreamingTV           | object   | No                                  |\n",
    "| StreamingMovies       | object   | Yes                                 |\n",
    "| PaperlessBilling      | object   | Yes                                 |\n",
    "| PaymentMethod         | object   | Credit Card (automatic)             |\n",
    "| Tenure                | float64  | 6.795513                            |\n",
    "| MonthlyCharge         | float64  | 171.449762                          |\n",
    "| Bandwidth_GB_Year     | float64  | 904.536110                          |\n",
    "| item1                 | int64    | 5                                   |\n",
    "| item2                 | int64    | 5                                   |\n",
    "| item3                 | int64    | 5                                   |\n",
    "| item4                 | int64    | 3                                   |\n",
    "| item5                 | int64    | 4                                   |\n",
    "| item6                 | int64    | 0                                   |\n",
    "| item7                 | int64    | 3                                   |\n",
    "| item8                 | int64    | 4                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a884b0be",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:300;font-size:16px\">\n",
    "  \n",
    "\n",
    "\n",
    "# C)\n",
    "\n",
    "### 1)\n",
    "\n",
    "\n",
    "&emsp;&emsp;The first step I will use to assess the data quality is to identify missing values.\n",
    "In python missing values can be detected with the df.isna().sum() function and its variations such as df.iloc[5].isna().sum()\n",
    "\n",
    "\n",
    "&emsp;&emsp;The second step I will use to assess the data quality is to identify duplicates rows based on customer_id column. I will do this with the pandas library with the df.duplicated()function. Duplicate rows can also be identifed based on a subset of columns such as\n",
    "df.duplicated(subset=['Customer_id']).\n",
    "\n",
    "\n",
    "&emsp;&emsp;The third step I will use to assess the data quality is to identify outliers. I will use the python describe() function first to check if further analysis is needed. I will identify outliers with frequency counts such as df['Your_Column_Name'].value_counts(), z-scores such as zscore(df[column_name]), or plot a histogram such as df['values'].hist() plt.show() with the matplotlib library.\n",
    "  \n",
    "  \n",
    "  \n",
    "### 2)\n",
    "   \n",
    "   \n",
    "&emsp;&emsp;This is an effective approach to assess the quality of the data set because it addresses several quality metrics such as outliers, duplicates, and missingness. The python libraries and functions used are effective at working on large data sets. This approach also accounts for the characteristics of the data. Histograms, frequency counts, and the describe() function can be used on categorical data to identify outliers, while z-scores are preferred for numerical data.\n",
    " \n",
    " \n",
    "\n",
    "### 3)\n",
    "\n",
    "\n",
    "&emsp;&emsp;Python and the matplotlib, pandas, and scipy library are a good choice for data cleaning on this project. One reason is that I am familiar with python language. Another reason is that python and the associated libraries automate a lot of the statistical work. Stats.z-scores will return the z-scores of the data in one step so you don't have to do each step manually to calculate the z-score for each data point. Python and the associated libraries also have related functions that can mitigate some of the data quality issues as well as identifying them.\n",
    "\n",
    "</span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d35edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Assuming your CSV file is named 'data.csv', adjust the file path as needed\n",
    "file_path = '/home/dj/skewl/d206/churn_raw_data.csv'\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Read the data from the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "#drop index column\n",
    "df = df.loc[:, ~df.columns.str.contains('Unnamed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf9bf1",
   "metadata": {},
   "source": [
    "# DETECTION STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c12da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaseOrder                  0\n",
      "Customer_id                0\n",
      "Interaction                0\n",
      "City                       0\n",
      "State                      0\n",
      "County                     0\n",
      "Zip                        0\n",
      "Lat                        0\n",
      "Lng                        0\n",
      "Population                 0\n",
      "Area                       0\n",
      "Timezone                   0\n",
      "Job                        0\n",
      "Children                2495\n",
      "Age                     2475\n",
      "Education                  0\n",
      "Employment                 0\n",
      "Income                  2490\n",
      "Marital                    0\n",
      "Gender                     0\n",
      "Churn                      0\n",
      "Outage_sec_perweek         0\n",
      "Email                      0\n",
      "Contacts                   0\n",
      "Yearly_equip_failure       0\n",
      "Techie                  2477\n",
      "Contract                   0\n",
      "Port_modem                 0\n",
      "Tablet                     0\n",
      "InternetService            0\n",
      "Phone                   1026\n",
      "Multiple                   0\n",
      "OnlineSecurity             0\n",
      "OnlineBackup               0\n",
      "DeviceProtection           0\n",
      "TechSupport              991\n",
      "StreamingTV                0\n",
      "StreamingMovies            0\n",
      "PaperlessBilling           0\n",
      "PaymentMethod              0\n",
      "Tenure                   931\n",
      "MonthlyCharge              0\n",
      "Bandwidth_GB_Year       1021\n",
      "item1                      0\n",
      "item2                      0\n",
      "item3                      0\n",
      "item4                      0\n",
      "item5                      0\n",
      "item6                      0\n",
      "item7                      0\n",
      "item8                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify missing values using isna() method\n",
    "missing_values = df.isna().sum()\n",
    "# Print DataFrame with True for missing values and False for non-missing values\n",
    "print(missing_values)\n",
    "\n",
    "# found lots of missing values here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e41823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to reset data\n",
    "def reset_data():\n",
    "    import pandas as pd\n",
    "    file_path = '/home/dj/skewl/d206/churn_raw_data.csv'\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    # Read the data from the CSV file into a DataFrame\n",
    "    global df\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.loc[:, ~df.columns.str.contains('Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a609c707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate rows \n",
    "duplicate_rows = df.duplicated([\"Customer_id\"]).sum()\n",
    "\n",
    "# Print duplicate rows   # found NO duplicate rows here!\n",
    "print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce360f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to list outliers by Z-score\n",
    "\n",
    "def get_outliers_z(col_name):\n",
    "    \n",
    "    df['zscore'] = zscore(df[col_name])\n",
    "    outliers = df.query('zscore > 3 | zscore < -3')\n",
    "    print(f\"number of outliers= {len(outliers)}\")\n",
    "    print(f\"\\n Z-score of outliers= \\n{outliers['zscore']}\")\n",
    "    del df['zscore']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "775ef4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to list outliers by interquartile range\n",
    "\n",
    "def get_iqr_outliers(col_name):\n",
    "    # calculate IQR for column Height\n",
    "    Q1 = df[col_name].quantile(0.25)\n",
    "    Q3 = df[col_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # identify outliers\n",
    "    threshold = 1.5\n",
    "    outliers = df[(df[col_name] < Q1 - threshold * IQR) | (df[col_name] > Q3 + threshold * IQR)]\n",
    "    print(f\"outliers = {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d26ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot histogram\n",
    "def plot_hist(col_name, num_bins, do_rotate=False):\n",
    "    plt.hist(df[col_name], bins=num_bins)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of {col_name}')\n",
    "    if do_rotate:\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bc6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print row count that matches a value\n",
    "def row_count_by_value(value):\n",
    "    \n",
    "    value_to_match = value\n",
    "    row_count_matching_value = (df == value_to_match).sum()\n",
    "    print(row_count_matching_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538c7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counts(col_name):\n",
    "    print(df[col_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefdd39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print missing values\n",
    "def print_desc(col_name):\n",
    "    print(df[col_name].describe())\n",
    "    print(f\"missing values= {df[col_name].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41469012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "plot_hist(\"City\",20)\n",
    "print_desc(\"City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4213c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d83f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no issues here\n",
    "print_desc(\"CaseOrder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no issues here\n",
    "print_desc(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no issues here\n",
    "print_desc(\"Interaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d100029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no issues\n",
    "print_desc(\"Customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbed6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no issues\n",
    "print_desc(\"County\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a problem here because this should be an int. Note the min value!\n",
    "print_desc(\"Zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7f892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d27f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Lng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26777647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#this could be bad data. There is 6000 places with 0 population according to census.\n",
    "#change this to int\n",
    "\n",
    "print_desc(\"Population\")\n",
    "plot_hist(\"Population\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4acf1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looks good. Equal distribution.\n",
    "print_desc(\"Area\")\n",
    "plot_hist(\"Area\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# something wrong. There should only be 24 timezones!\n",
    "print_desc(\"Timezone\")\n",
    "df[\"Timezone\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadadda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e464af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of missing values change to int and impute\n",
    "print_desc(\"Children\")\n",
    "plot_hist(\"Children\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e00cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of missing values change to int and impute.\n",
    "print_desc(\"Age\")\n",
    "plot_hist(\"Age\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9588da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Education\")\n",
    "plot_hist(\"Education\",30,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a447ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Employment\")\n",
    "plot_hist(\"Employment\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed62b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is bad data because there is so many missing values.\n",
    "print_desc(\"Income\")\n",
    "plot_hist(\"Income\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Marital\")\n",
    "print_counts(\"Marital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88440caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Gender\")\n",
    "print_counts(\"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced742e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Churn\")\n",
    "print_counts(\"Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to drop the rows with negative values\n",
    "print_desc(\"Outage_sec_perweek\")\n",
    "plot_hist(\"Outage_sec_perweek\",50)\n",
    "get_outliers_z(\"Outage_sec_perweek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5effc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change this to int!\n",
    "print_desc(\"Contacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db337097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change this to Int!\n",
    "print_desc(\"Yearly_equip_failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44974714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of missing values. Need to impute\n",
    "print_desc(\"Techie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6383c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Contract\")\n",
    "print_counts(\"Contract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f227c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Port_modem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Tablet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"InternetService\")\n",
    "print_counts(\"InternetService\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1dd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing a lot of values\n",
    "print_desc(\"Phone\")\n",
    "print_counts(\"Phone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"Multiple\")\n",
    "print_counts(\"Multiple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"OnlineSecurity\")\n",
    "print_counts(\"OnlineSecurity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"DeviceProtection\")\n",
    "print_counts(\"DeviceProtection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of missing values here\n",
    "print_desc(\"TechSupport\")\n",
    "print_counts(\"TechSupport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ffe239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"StreamingTV\")\n",
    "print_counts(\"StreamingTV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ace3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"StreamingMovies\")\n",
    "print_counts(\"StreamingMovies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"PaperlessBilling\")\n",
    "print_counts(\"PaperlessBilling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"PaymentMethod\")\n",
    "print_counts(\"PaymentMethod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf01a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of missing values!\n",
    "print_desc(\"Tenure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good\n",
    "print_desc(\"MonthlyCharge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66483002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of missing values here!\n",
    "print_desc(\"Bandwidth_GB_Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eff203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad227411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05651d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7737c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks good but change to int\n",
    "print_desc(\"item8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e64da",
   "metadata": {},
   "source": [
    "# CLEAN UP STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f1694-36b9-4c98-8e19-36c0ebf28f88",
   "metadata": {},
   "source": [
    "  # D\n",
    "   ## 1)\n",
    "    Duplicate rows:\n",
    "     I could not find any duplicate rows based on the columns 'Customer_id'.\n",
    "\n",
    "    Missing values:\n",
    "      I found missing values in the columns 'Children', 'Age', 'Income', 'Techie','Phone','TechSupport','Tenure','Bandwith_GB_Year'.\n",
    "\n",
    "    Outliers and anomalies:\n",
    "       While z-scores and IQR analysis of many columns showed that there were outliers, I have decided that not all things have a normal distribution and the values seemed reasonable. The only column that has data anomalies is 'Outage_sec_per_week' which has negative values that should be cleaned up.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c8fab-be91-4c42-b5d7-be6bd24dbc39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2)\n",
    "\n",
    "        There were no duplicate rows according to my criteria so nothing will be done there. Missing values will be imputed using various techniques. I think this will preserve the data integrity better than dropping the rows with missing values. Dropping the rows would significantly affect the data set because some columns have thousands of missing values. The method used varies based on the column so I have provided a justification and summary for each column next to the annotated code cell.\n",
    "\n",
    "\n",
    "\n",
    "### See below for detailed annotation of data cleaning above each code cell please."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6ddbd-6246-484e-bda8-f81e33c357c4",
   "metadata": {},
   "source": [
    "## 3)\n",
    "\n",
    "    I was able to mitigate all the anomalies without changing the distribution significantly. The method used varies on the column so I have provided a justification and summary for each column next to the annotated code cell.\n",
    "### See below for detailed annotation of data cleaning outcome above each code cell please."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed0e81-2d02-4068-a405-9da6fef51c7b",
   "metadata": {},
   "source": [
    "### 4)\n",
    "\n",
    "\n",
    "### annotated clean up implementation code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8077abd-bdf6-4355-bff8-0582a81907fb",
   "metadata": {},
   "source": [
    "### 5) \n",
    "cleaned .csv file will be attached as separate file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca3516-9e6b-4c64-a688-e88235ae8220",
   "metadata": {},
   "source": [
    " ### children\n",
    "\n",
    " #### justification\n",
    "       I used the bfill() and ffill() function to fill in the missing values because I believe it distributes the missing values more equally than using the mode or median. I can not use the interpolate() function because it would input floats into the missing values and we can't have 1.5 children. I changed the data type to int because children are more accurately described as integers.\n",
    "\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution significantly of the data or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9856c6-f1e8-43f0-94be-2a46176378b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values in children with ffill and bffill method\n",
    "df['Children'].ffill(inplace=True)\n",
    "df['Children'].bfill(inplace=True)\n",
    "df['Children'] = df['Children'].astype(int)\n",
    "print_desc(\"Children\")\n",
    "plot_hist(\"Children\",30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57172401-e8f3-421d-aa84-d2721ef5a0e0",
   "metadata": {},
   "source": [
    "### Age\n",
    "\n",
    " #### justification\n",
    "       I used the bfill() and ffill() function to fill in the missing values because I believe it distributes the missing values more equally than using the mode or median. I can not use the interpolate() function because it would input floats into the missing values and we can't have 1.5 for an age. I changed the data type to int because age is more accurately described as integers.\n",
    "\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution significantly of the data or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e6730-89f8-4388-8135-2a1585c7f54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace missing values with ffill and bffill method and change type to int\n",
    "df['Age'].ffill(inplace=True)\n",
    "df['Age'].bfill(inplace=True)\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "print_desc(\"Age\")\n",
    "plot_hist(\"Age\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31884b15-82cd-47e4-9619-1baa3fba879b",
   "metadata": {},
   "source": [
    "### Income\n",
    "\n",
    " #### justification\n",
    "       I used linear interpolation because this is a float and will give us the most equal distribution of missing value replacement.\n",
    "\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution of the data significantly or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea051931-bcab-4b0f-8c09-fcc878052b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with linear interpolaton\n",
    "df['Income'].interpolate(method='linear', inplace=True)\n",
    "print_desc(\"Income\")\n",
    "plot_hist(\"Income\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00c130-e5ff-4f5b-a2be-1551b23250a8",
   "metadata": {},
   "source": [
    "### Techie\n",
    "\n",
    " #### justification\n",
    "      I replaced the missing values with 'No' because I think that techies would be more likely to check the techie box in the questionnaire than non techies. Also I think it is better for the company to treat more people as non technical unless we know otherwise.\n",
    "\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution of the data significantly or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad0edf-b82a-4ff8-8859-e7d2fb655b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with no\n",
    "df['Techie'] = df['Techie'].fillna(\"No\")\n",
    "print_desc(\"Techie\")\n",
    "plot_hist(\"Techie\",3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb7dd5-61c0-44d6-b847-4e1a36b95493",
   "metadata": {},
   "source": [
    "### Phone\n",
    "\n",
    " #### justification\n",
    "      I replaced the missing values with the value from the 'Multiple' column because it logically follows that if a person has multiple lines they will have at least one phone.\n",
    "\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution of the data significantly or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c2e1b-85c4-44a8-bc89-5456a24af841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute missing values from multiple column\n",
    "df['Phone'] = df['Phone'].fillna(df['Multiple'])\n",
    "print_desc(\"Phone\")\n",
    "plot_hist(\"Phone\",3)\n",
    "print_counts(\"Phone\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b82a3f-91f4-40d0-8f13-9cb27b2c3ae1",
   "metadata": {},
   "source": [
    "### TechSupport\n",
    "\n",
    " #### justification\n",
    "      I replaced the missing values with the value from the 'DeviceProtection' column because it logically follows that if a person has DeviceProtection they will also have tech support.\n",
    "\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution of the data significantly or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cab1c-0dfa-4c33-9d51-28ca8eb3b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute missing values from multiple DeviceProtection column\n",
    "df['TechSupport'] = df['TechSupport'].fillna(df['DeviceProtection'])\n",
    "print_desc(\"TechSupport\")\n",
    "plot_hist(\"TechSupport\",3)\n",
    "print_counts(\"TechSupport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d219f31-5646-4b3f-ba0c-3da27d6b711a",
   "metadata": {},
   "source": [
    "### Tenure\n",
    "\n",
    " #### justification\n",
    "       I used the bfill() and ffill() function to fill in the missing values because I believe distributes it the missing values more equally than using the mode or median. I can not use the interpolate() function because it would input floats into the missing values and we can't have 1.5 for a tenure. I changed the data type to int because tenure is more accurately described as integers.\n",
    "\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution of the data significantly or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b18b3-942d-42cf-b3dd-7772d3b24ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#replace missing values with ffill and bffill method and change type to int\n",
    "df['Tenure'].ffill(inplace=True)\n",
    "df['Tenure'].bfill(inplace=True)\n",
    "df['Tenure'] = df['Tenure'].astype(int)\n",
    "print_desc(\"Tenure\")\n",
    "plot_hist(\"Tenure\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d284b-be9d-44ca-ad12-94e71597d6fc",
   "metadata": {},
   "source": [
    "### Bandwith_GB_year\n",
    "\n",
    " #### justification\n",
    "      I used linear interpolation function to fill in the missing values because I believe distributes the missing values more equally than using the mode or median. Also it works well on floats.\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution of the data significantly or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bfce7d-dbf8-4317-b604-30d344269f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with mode\n",
    "df['Bandwidth_GB_Year'].interpolate(method='linear', inplace=True)\n",
    "print_desc('Bandwidth_GB_Year')\n",
    "plot_hist('Bandwidth_GB_Year',30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c48f8a-6ab0-457d-8ac1-f917c3dbfa71",
   "metadata": {},
   "source": [
    "### Outage_sec_perweek\n",
    "\n",
    " #### justification\n",
    "      I transformed this data by changing the negative values to positive because I made the assumption that the negative sign was a mistake.\n",
    " #### summarized outcome\n",
    "        This method works well and did not change the distribution of the data very much or cause any outliers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bbcab-4b31-409c-a778-7e4cb9aa8c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make negative values positive.\n",
    "df.loc[df['Outage_sec_perweek'] < 0, 'Outage_sec_perweek'] *= -1\n",
    "print_desc(\"Outage_sec_perweek\")\n",
    "plot_hist(\"Outage_sec_perweek\",30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5c40e-9874-4123-8da3-fc1c226425a5",
   "metadata": {},
   "source": [
    "#### all missing values have been imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3bcdd-5dad-40fa-99d3-cfa4e5471402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values using isna() method\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)\n",
    "# missing values are replaced with meaningful data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766dd32-fc65-41b0-8438-9315f867ed0b",
   "metadata": {},
   "source": [
    "### print cleaned data to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6520e-e596-4b13-97cc-5833b6e47648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print DataFrame to CSV file\n",
    "df.to_csv('clean-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5fe50-eb18-44ce-9383-9bfceb1ac5e6",
   "metadata": {},
   "source": [
    "## 6)\n",
    "\n",
    "        Some limitations of the data cleaning process are that when a significant of values are missing, replacing them with any method changes the distribution to various degrees based on the amount of missing values. Regardless of the technique to replace the values, the missing values still skew the data. Another limitation is that without specific domain knowledge of the data set it is difficult to discrern which values are actually outliers and which are reasonable values. Z-scores and IQR techniques may indicate outliers even though the data is reasonable because the distribution for that variable is not normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2dc5c1-27fb-40ec-be47-85e60679dcc9",
   "metadata": {},
   "source": [
    "## 7)\n",
    "        The limitations summarized in part D6 will affect the analysis of the question from part A because the data had bad values that were negative or missing values. As a data analyst I have no Idea idea if they were bad values or they were just input incorrectly as negative. The approach I took for the 'Bandwithd_BG_Year' Column assumed that they just needed to be converted to positive values. If my assumption is wrong then the data will be skewed and my analysis may come to an incorrect conclusion. The missing values being imputed will change the distribution of the data. In summary, all missing data and the techniques used to clean it may have an affect on the analysis. I may come to the wrong conclusion about the correlation between the data and churn due to these limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec2b77-20ab-4371-be2a-2e3edd4458b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "data = df.select_dtypes(include='number')\n",
    "print(data.shape[1])\n",
    "#normalize data\n",
    "data_normalized=(data-data.mean())/data.std()\n",
    "#start with max components\n",
    "pca = PCA(n_components=data.shape[1])\n",
    "\n",
    "#fit pca model to our data\n",
    "pca.fit(data_normalized)\n",
    "#transform data set to 23 PCA components\n",
    "data_pca = pd.DataFrame(pca.transform(data_normalized),     \n",
    "     columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9',\n",
    "             'PC10','PC11','PC12','PC13','PC14','PC15','PC16','PC17'\n",
    "              ,'PC18','PC19','PC20','PC21','PC22','PC23'])\n",
    "\n",
    "loadings = pd.DataFrame(pca.components_.T,\n",
    "     columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9',\n",
    "             'PC10','PC11','PC12','PC13','PC14','PC15','PC16','PC17'\n",
    "              ,'PC18','PC19','PC20','PC21','PC22','PC23'],\n",
    "     index=data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af41b01-23eb-4a4e-9ee9-32e009f6a06f",
   "metadata": {},
   "source": [
    "## E\n",
    "\n",
    "1) The initial total number of principal components will be 23 because that is how many numeric fields we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27892aa-979e-4df0-86d7-e42777da7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(loadings.head(23))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71692c3a-d976-472d-ba4b-bf5495845eed",
   "metadata": {},
   "source": [
    "## 2)\n",
    "\n",
    "  I chose to use 13 PCA components because all components beyond that have an eigenvalue of less than one. I am including plots of the eigenvalues and explained variance. I could use the elbow of the explained variance but I think the eigenvalues are more accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368849d-eeb5-484c-bef0-fad06e770a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('explained variance')\n",
    "plt.show()\n",
    "\n",
    "cov_matrix = np.dot(data_normalized.T, data_normalized) / data.shape[0]\n",
    "eigenvalues = [np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)) for\n",
    "eigenvector in pca.components_]\n",
    "\n",
    "plt.plot(eigenvalues)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('eigenvalue')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cfd25-78c0-4427-8677-abb1791112fa",
   "metadata": {},
   "source": [
    "## 3)\n",
    " I think the organization can benefit from PCA because it can simplify the visual analysis of the data when presenting it to stakeholders. Instead of\n",
    " showing them what could be hundreds of variables that may not have much effect on the analysis, we can reduce the variables and keep most of the accuracy of the model. Another benefit is noise filtering. The originization can benefit from PCA by having the benefit of using a model that is more accurate because it better identifies meaningful patterns. This will lead to better predictions and better models the organization uses to make business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59709c-42c0-4d9f-85a3-e4ac1e9e2e92",
   "metadata": {},
   "source": [
    "## F)\n",
    "\n",
    "panopto video submitted in links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4889cda-5593-4208-b077-c70640237d9d",
   "metadata": {},
   "source": [
    "## G)\n",
    "\n",
    "Citations:\n",
    "\n",
    "Pandas documentation# (no date) pandas documentation - pandas 2.2.1 documentation. Available at: https://pandas.pydata.org/docs/ (Accessed: 06 April 2024). \n",
    "\n",
    "\n",
    "\n",
    "Project jupyter documentation# (no date) Project Jupyter Documentation - Jupyter Documentation 4.1.1 alpha documentation. Available at: https://docs.jupyter.org/en/latest/ (Accessed: 06 April 2024). \n",
    "\n",
    "\n",
    "Learn  scikit. Available at: https://scikit-learn.org/stable/ (Accessed: 06 April 2024). \n",
    "\n",
    "GfG (2024) How to drop unnamed column in pandas DataFrame, GeeksforGeeks. Available at: https://www.geeksforgeeks.org/how-to-drop-unnamed-column-in-pandas-dataframe/ (Accessed: 06 April 2024). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be845f-e592-4fe4-9bd0-932263d8510f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
